{
  "$id": "$gai-technique/citation_manipulation",
  "$schema": "../schema/technique.schema.json",
  "$type": "technique",
  "description": "The adversary manipulates citations provided by the AI system to add trustworthiness to their social engineering attack. Variants include providing the wrong citation, making up a new one or providing the right citation for the wrong data.",
  "external_references": [
    {
      "href": "https://labs.zenity.io/p/phantom-references-microsoft-copilot",
      "source": "Zenity",
      "title": "Phantom References in Microsoft Copilot."
    }
  ],
  "framework_references": [
    {
      "framework_id": "AML.T0067.000",
      "framework_name": "MITRE ATLAS",
      "href": "https://atlas.mitre.org/techniques/AML.T0067.000"
    }
  ],
  "name": "Citation Manipulation",
  "object_references": [
    {
      "$id": "$gai-technique/llm_trusted_output_components_manipulation",
      "$type": "technique",
      "description": "Sub-technique of",
      "is_sub_object": true
    },
    {
      "$id": "$gai-technique/citation_silencing",
      "$type": "technique",
      "description": "An adjacent technique which also includes adversary control over citations."
    },
    {
      "$id": "$gai-entity/michael_bargury",
      "$type": "entity",
      "description": "Demonstrated by"
    },
    {
      "$id": "$gai-entity/tamir_ishay_sharbat",
      "$type": "entity",
      "description": "Demonstrated by"
    },
    {
      "$id": "$gai-entity/gal_malka",
      "$type": "entity",
      "description": "Demonstrated by"
    }
  ]
}
