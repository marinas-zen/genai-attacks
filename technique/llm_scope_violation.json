{
  "$id": "$gai-technique/llm_scope_violation",
  "$schema": "../schema/technique.schema.json",
  "$type": "technique",
  "description": "An LLM Scope Violation occurs when attacker-controlled input causes the LLM to access or act upon trusted data in the model's context, without the user's explicit consent. This violates the Principle of Least Privilege by enabling untrusted content to influence the model's behavior toward trusted internal context. For example, an external email, originating from outside the organization, should not be able to fetch and handle sensitive data which originates from within the organization.",
  "external_references": [
    {
      "href": "https://www.aim.security/lp/aim-labs-echoleak-blogpost",
      "source": "Aim Security",
      "title": "Breaking down 'EchoLeak', the First Zero-Click AI Vulnerability Enabling Data Exfiltration from Microsoft 365 Copilot"
    },
    {
      "href": "https://embracethered.com/blog/posts/2024/m365-copilot-prompt-injection-tool-invocation-and-data-exfil-using-ascii-smuggling/",
      "source": "Embrace the Red",
      "title": "Microsoft Copilot: From Prompt Injection to Exfiltration of Personal Information."
    }
  ],
  "framework_references": [],
  "name": "LLM Scope Violation",
  "object_references": [
    {
      "$id": "$gai-tactic/privilege_escalation",
      "$type": "tactic",
      "description": "An adversary can escalate privileges by abusing LLM Scope Violation."
    },
    {
      "$id": "$gai-entity/johann_rehberger",
      "$type": "entity",
      "description": "Demonstrated by"
    },
    {
      "$id": "$gai-entity/aim_security",
      "$type": "entity",
      "description": "Demonstrated by"
    }
  ]
}
